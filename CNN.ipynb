{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from my_utils import *\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import timm\n",
    "from my_utils import plot_durations\n",
    "import warnings\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model_list.model import NetworkNvidia\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "deterministic = True\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic:\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG={\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else \"cpu\"),\n",
    "    'EPOCH':1000,\n",
    "    'BATCH_SIZE':64\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_length = 0\n",
    "# for dir_path in os.listdir('expert_data'):\n",
    "#     with open(os.path.join('expert_data', dir_path, 'len.txt')) as f:\n",
    "#         total_length += int(f.readline())\n",
    "# print(\"TOTAL_LENGTH: \",total_length)\n",
    "# expert_states = np.empty((total_length, 9, 112, 256), dtype=np.float32)\n",
    "# expert_commands = np.empty((total_length, 3), dtype=np.float32)\n",
    "# expert_speeds = np.empty((total_length, 1), dtype=np.float32)\n",
    "# expert_actions = np.empty((total_length, 3), dtype=np.float32)\n",
    "# loaded_length = 0\n",
    "# for dir in tqdm(os.listdir('expert_data')):\n",
    "#     np_states = np.load(os.path.join('expert_data', dir, 'expert_states.npy'))\n",
    "#     np_commands = np.load(os.path.join('expert_data', dir, 'expert_commands.npy'))\n",
    "#     np_speeds = np.load(os.path.join('expert_data', dir, 'expert_speeds.npy'))\n",
    "#     np_actions = np.load(os.path.join('expert_data', dir, 'expert_actions.npy'))\n",
    "\n",
    "#     episode_length = np_states.shape[0]\n",
    "#     expert_states[loaded_length: loaded_length + episode_length] = np_states\n",
    "#     expert_commands[loaded_length: loaded_length + episode_length] = np_commands\n",
    "#     expert_speeds[loaded_length: loaded_length + episode_length] = np_speeds\n",
    "#     expert_actions[loaded_length: loaded_length + episode_length] = np_actions\n",
    "\n",
    "#     loaded_length += episode_length\n",
    "\n",
    "# print('data loaded!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.save('./save_data/expert_states_front_view_2.npy',expert_states,)\n",
    "# # np.save('./save_data/expert_commands_front_view_2.npy',expert_commands)\n",
    "# # np.save('./save_data/expert_speeds_front_view_2.npy',expert_speeds)\n",
    "# # np.save('./save_data/expert_actions_front_view_2.npy',expert_actions)\n",
    "\n",
    "# expert_states=np.load('./save_data/expert_states_front_view_2.npy')\n",
    "# expert_commands=np.load('./save_data/expert_commands_front_view_2.npy')\n",
    "# expert_speeds=np.load('./save_data/expert_speeds_front_view_2.npy')\n",
    "# expert_actions=np.load('./save_data/expert_actions_front_view_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio = 0.85\n",
    "# num_states = len(expert_states)\n",
    "# expert_states_train = expert_states[: int(ratio * num_states)]\n",
    "# expert_commands_train = expert_commands[: int(ratio * num_states)]\n",
    "# expert_speeds_train = expert_speeds[: int(ratio * num_states)]\n",
    "# expert_actions_train = expert_actions[: int(ratio * num_states)]\n",
    "# expert_states_val = expert_states[int(ratio * num_states):]\n",
    "# expert_commands_val = expert_commands[int(ratio * num_states):]\n",
    "# expert_speeds_val = expert_speeds[int(ratio * num_states):]\n",
    "# expert_actions_val = expert_actions[int(ratio * num_states):]\n",
    "# print(\"train_data: \",len(expert_states_train))\n",
    "# print(\"test_data: \",len(expert_states_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steering_angles = expert_actions_train[:, 1]\n",
    "# throttle_data = expert_actions_train[:, 0]\n",
    "# break_data = expert_actions_train[:, 2]\n",
    "# expert_states = expert_states_train  # 이미지 데이터 (전체 데이터)\n",
    "# labels=steering_angles = expert_actions_train[:, 1]\n",
    "# labels = np.round(labels, decimals=3)\n",
    "# label_counts=Counter(labels)\n",
    "\n",
    "# sorted_counts = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# # 상위 60% 레이블만 선택\n",
    "# top_60_percent_count = int(len(sorted_counts) * 0.6)\n",
    "# top_60_percent_labels = sorted_counts[:top_60_percent_count]\n",
    "# min_value_label = min(top_60_percent_labels, key=lambda x: x[1])\n",
    "\n",
    "# print(\"label_counts: \",label_counts)\n",
    "# # min_vlaue=min(label_counts.values())\n",
    "# # print(\"최소 카운트: \",min_vlaue)\n",
    "# # print(\"길이: \", len(label_counts.values()))\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"top_60_percent_count: \",top_60_percent_count)\n",
    "# print(\"top_60_percent_labels: \",top_60_percent_labels)\n",
    "# print(\"상위 60% 레이블 중 최소 갯수를 가진 레이블과 값: \", min_value_label)\n",
    "# print(\"해당 레이블의 값: \", min_value_label[0])\n",
    "# print(\"해당 레이블의 갯수: \", min_value_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_angles = expert_actions_train[:, 1]\n",
    "throttle_data = expert_actions_train[:, 0]\n",
    "break_data = expert_actions_train[:, 2]\n",
    "expert_states = expert_states_train  # 이미지 데이터 (전체 데이터)\n",
    "labels=steering_angles = expert_actions_train[:, 1]\n",
    "labels = np.round(labels, decimals=3)\n",
    "label_counts=Counter(labels)\n",
    "print(\"label_counts: \",label_counts)\n",
    "min_vlaue=min(label_counts.values())\n",
    "print(\"최소 카운트: \",min_vlaue)\n",
    "print(\"길이: \", len(label_counts.values()))\n",
    "cut_count=5\n",
    "min_count=30 # 최소 카운트 100개\n",
    "max_count=400\n",
    "erase_per=60\n",
    "balanced_indices = []\n",
    "\n",
    "for label,count in tqdm(label_counts.items()):\n",
    "\n",
    "    # if count<cut_count:\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     label_indices=np.where(labels==label)[0]\n",
    "    #     if count<min_count:\n",
    "    #         sampled_indices = np.random.choice(label_indices, min_count, replace=True)\n",
    "    #     else:\n",
    "    #         sampled_indices =np.random.choice(label_indices, max_count, replace=True)\n",
    "    if count>cut_count:\n",
    "        label_indices=np.where(labels==label)[0]\n",
    "        if max_count>count:\n",
    "            sampled_indices =np.random.choice(label_indices, count, replace=True)\n",
    "        else:\n",
    "            sampled_indices =np.random.choice(label_indices, max_count, replace=True)\n",
    "    #     if label<0.03 and label>-0.03:\n",
    "    #         k=int(count*(erase_per)/100)\n",
    "    #         t=count-k\n",
    "    #         sampled_indices = np.random.choice(label_indices, t, replace=True)\n",
    "    #     else:\n",
    "    #         sampled_indices =np.random.choice(label_indices, count, replace=True)\n",
    "        balanced_indices.extend(sampled_indices)\n",
    "index=sorted(balanced_indices)\n",
    "\n",
    "balanced_expert_states = np.array(expert_states[index]) # 선택된 인덱스에 맞는 이미지 추출\n",
    "balanced_throttle_data = np.array(throttle_data[index]).reshape(-1,1)\n",
    "balanced_break_data = np.array(break_data[index]).reshape(-1,1)\n",
    "balanced_steering_angles = np.array(labels[index]).reshape(-1,1)\n",
    "balanced_speed=np.array(expert_speeds_train[index])\n",
    "balanced_command=np.array(expert_commands_train[index])\n",
    "\n",
    "action = np.concatenate((balanced_throttle_data, balanced_steering_angles, balanced_break_data), axis=1)\n",
    "print(action.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./save_data/norm_steering_expert_states_5cut_400_round3_v5.npy',balanced_expert_states)\n",
    "# np.save('./save_data/norm_steering_expert_action_5cut_400_round3_v5.npy',action)\n",
    "# np.save('./save_data/norm_steering_expert_speed_5cut_400_round3_v5.npy',balanced_speed)\n",
    "# np.save('./save_data/norm_steering_expert_command_5cut_400_round3_v5.npy',balanced_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5cut_4oo round3_v4 x 지그재그로 가는듯..? 스티어링만 0.0018이 최대 90x256\n",
    "#5cut_400_round4_v4\n",
    "#5cut_200_round4_v4 지금"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_steering_angles_counts=Counter(balanced_steering_angles.reshape(-1))\n",
    "# print(\"balanced_steering_angles_counts: \",balanced_steering_angles_counts)\n",
    "# min_vlaue=min(balanced_steering_angles_counts.values())\n",
    "# print(\"최소 카운트: \",min_vlaue)\n",
    "# print(\"길이: \", len(balanced_steering_angles_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_states_train=np.load('./save_data/norm_steering_expert_states_5cut_400_round3_v5.npy')\n",
    "expert_actions_train=np.load('./save_data/norm_steering_expert_action_5cut_400_round3_v5.npy')\n",
    "expert_speeds_train=np.load('./save_data/norm_steering_expert_speed_5cut_400_round3_v5.npy')\n",
    "expert_commands_train=np.load('./save_data/norm_steering_expert_command_5cut_400_round3_v5.npy')\n",
    "\n",
    "expert_states_val=np.load('./save_data/expert_states_val.npy')\n",
    "expert_actions_val=np.load('./save_data/expert_actions_val.npy')\n",
    "expert_speeds_val=np.load('./save_data/expert_speeds_val.npy')\n",
    "expert_commands_val=np.load('./save_data/expert_commands_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(expert_actions_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "class RandomTranslate(object):\n",
    "    def __call__(self, image, steering_angle, range_x=80, range_y=20):\n",
    "\n",
    "        trans_x = range_x * (np.random.rand() - 0.5)\n",
    "        trans_y = range_y * (np.random.rand() - 0.5)\n",
    "        \n",
    "        #steering_angle += trans_x * 0.002\n",
    "        #trans_m = torch.tensor([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "        #height, width = image.shape[1], image.shape[2]\n",
    "        affine_transform = T.functional.affine(image, angle=0, translate=(trans_x, trans_y), scale=1.0, shear=[0, 0])\n",
    "        return affine_transform, steering_angle\n",
    "class RandFlip(object):\n",
    "    \n",
    "    def __call__(self, image,action):\n",
    "        if random.randint(0, 1) == 1:\n",
    "            image = torch.flip(image, [-1])  \n",
    "            action = -action\n",
    "        \n",
    "        return image,action\n",
    "    \n",
    "class RandBrightness(object):\n",
    "\n",
    "    def __call__(self, image,mode):\n",
    "        img = image# 이미지를 [H, W, C]에서 [C, H, W]로 변환\n",
    "    \n",
    "            \n",
    "        if mode=='channel_9' or mode=='concat':\n",
    "            num=random.randint(0,3)\n",
    "            if num==0:\n",
    "                img[:3,:,:] = torchvision.transforms.functional.adjust_brightness(img[:3,:,:], 1 + np.random.uniform(-0.5, 0.5))\n",
    "            elif num==1:\n",
    "                \n",
    "                img[3:6,:,:] = torchvision.transforms.functional.adjust_brightness(img[3:6,:,:], 1 + np.random.uniform(-0.5, 0.5))\n",
    "            elif num==2:\n",
    "                \n",
    "                img[6:,:,:] = torchvision.transforms.functional.adjust_brightness(img[6:,:,:], 1 + np.random.uniform(-0.5, 0.5))\n",
    "            img=torch.clamp(img,min=0,max=1)\n",
    "        return img\n",
    "class RandRotateView(object):\n",
    "    def __call__(self, image,action,target_mode):\n",
    "        if random.randint(0, 3) == 1 and abs(action) < 0.3:\n",
    "            rotate = random.uniform(-30, 30)\n",
    "            delta_angle = rotate / 60\n",
    "            image = torchvision.transforms.functional.rotate(image, rotate)  # ndimage.rotate 대신 torchvision의 rotate 사용\n",
    "\n",
    "            if target_mode == 'steer':\n",
    "                action += delta_angle\n",
    "        return image, action\n",
    "    \n",
    "class RandRotation(object):\n",
    "    def __call__(self, image):\n",
    "        rotate = random.uniform(-1, 1)\n",
    "        image = torchvision.transforms.functional.rotate(image, rotate)\n",
    "        image = torch.clip(image, 0, 1)\n",
    "        return image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image, action,speed,command,transforms=None,mode='center',target_mode='steer',train_mode=True):\n",
    "        self.image = image\n",
    "        self.action = action\n",
    "        self.command=command\n",
    "        self.transforms = transforms\n",
    "        self.mode=mode\n",
    "        self.target_mode=target_mode\n",
    "        self.train_mode=train_mode\n",
    "        self.speed=torch.FloatTensor(speed)\n",
    "        self.RandFlip=RandFlip()\n",
    "        self.RandBrightness=RandBrightness()\n",
    "        self.RandRotation=RandRotation()\n",
    "        self.RandRotateView=RandRotateView()\n",
    "        self.RandomTranslate=RandomTranslate()\n",
    "        #self.resize=torchvision.transforms.Resize((320,320))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image=self.image[index].transpose(1,2,0)/255.\n",
    "        image=image[22:,:,:]\n",
    "        if self.target_mode=='steer':\n",
    "            label=self.action[index][1]\n",
    "            label=np.round(label,3)\n",
    "            label=torch.FloatTensor([label])\n",
    "            throttle=self.action[index][0]\n",
    "            throttle=torch.FloatTensor([throttle])\n",
    "            command=torch.FloatTensor(self.command[index])\n",
    "        # elif self.target_mode=='throttle':\n",
    "        elif self.target_mode=='breake':\n",
    "            label=self.action[index][2]\n",
    "\n",
    "            label=torch.FloatTensor([label])\n",
    "        # left=image[:,:,:3]\n",
    "        # center=image[:,:,3:6]\n",
    "        # right=image[:,:,6:]\n",
    "        \n",
    "        \n",
    "        if self.mode=='center':\n",
    "            center=image[:,:,3:6]\n",
    "\n",
    "            concat_image=center\n",
    "            if self.train_mode==True:\n",
    "                concat_image,label=self.RandFlip(concat_image,label)\n",
    "                concat_image=self.RandBrightness(concat_image,self.mode)\n",
    "                concat_image=self.RandRotation(concat_image,)\n",
    "                concat_image,label=self.RandRotateView(concat_image,label,self.target_mode)\n",
    "        elif self.mode=='channel_9' or self.mode=='concat':\n",
    "            if self.train_mode==True:\n",
    "                image = self.transforms(image=image)['image']\n",
    "                image,label=self.RandFlip(image,label)\n",
    "                image=self.RandBrightness(image,self.mode)\n",
    "                image=self.RandRotation(image)\n",
    "                image,label=self.RandRotateView(image,label,self.target_mode)\n",
    "                image,label=self.RandomTranslate(image,label)\n",
    "                #image=self.resize(image)\n",
    "            elif self.train_mode==False:\n",
    "                image = self.transforms(image=image)['image']\n",
    "\n",
    "                # print(label)\n",
    "                #image=self.resize(image)\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "        if self.transforms is not None:\n",
    "            if self.mode=='total':\n",
    "                \n",
    "                if self.train_mode==True:\n",
    "                    image = self.transforms(image=image)['image']\n",
    "                    image=torch.cat((image[:3,:,:],image[3:6,:,:],image[6:,:,:]),dim=-1)\n",
    "                    \n",
    "                   \n",
    "                    image,label=self.RandFlip(image,label)\n",
    "                    image=self.RandBrightness(image,self.mode)\n",
    "                    image=self.RandRotation(image)\n",
    "                    image,label=self.RandRotateView(image,label,self.target_mode)\n",
    "                    #image=self.resize(image)\n",
    "                    \n",
    "\n",
    "                elif self.train_mode==False:\n",
    "                    #label=label-steering_min/steering_max-steering_min\n",
    "                    image = self.transforms(image=image)['image']\n",
    "                    image=torch.cat((image[:3,:,:],image[3:6,:,:],image[6:,:,:]),dim=-1)\n",
    "                    #image=self.resize(image)\n",
    "                    \n",
    "\n",
    "        \n",
    "        if self.action is not None:\n",
    "            s=self.speed[index]\n",
    "            image=image\n",
    "            steering=torch.round(label * 1000) / 1000 #3자리수에서 올림\n",
    "            label=torch.cat((throttle,steering),dim=-1)\n",
    "\n",
    "            return image,s,command,label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transform=A.Compose([\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.3),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transform=A.Compose([\n",
    "    #A.Resize(320,320),\n",
    "   \n",
    "    ToTensorV2()\n",
    "])\n",
    "target_label_mode='steer'\n",
    "camera_view='channel_9' #channel_9, total,center,concat\n",
    "train_transform_dataset=CustomDataset(expert_states_train,expert_actions_train,expert_speeds_train,expert_commands_train,train_transform,mode=camera_view,target_mode=target_label_mode,train_mode=True)\n",
    "val_transform_dataset=CustomDataset(expert_states_val,expert_actions_val,expert_speeds_val,expert_commands_val,test_transform,mode=camera_view,target_mode=target_label_mode,train_mode=False)\n",
    "train_loader=DataLoader(train_transform_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=True)\n",
    "test_loader=DataLoader(val_transform_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))\n",
    "image,speed,command,label=train_transform_dataset.__getitem__(300)\n",
    "print(label)\n",
    "print(speed)\n",
    "print(command)\n",
    "print(image.shape)\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image[0:3,:,:].permute(1,2,0))\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image[3:6,:,:].permute(1,2,0))\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image[6:9,:,:].permute(1,2,0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader=DataLoader(train_transform_dataset,batch_size=1,shuffle=True)\n",
    "# test=torch.tensor([0,0,0])\n",
    "# for image,speed,command,label in tqdm(train_loader):\n",
    "#     branch_idx = torch.argmax(command, dim=1)[0]\n",
    "#     test[branch_idx]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self,model_name,class_number=1):\n",
    "        super(BaseModel,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Conv2d(9,3,kernel_size=3,stride=1,padding=1)\n",
    "        self.batch_norm=nn.BatchNorm2d(3)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "       \n",
    "        self.basemodel=timm.create_model(model_name,pretrained=False,num_classes=512)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "        ###############Mesaurement###############\n",
    "\n",
    "        self.measure_fc1=nn.Linear(1,128)\n",
    "        self.measure_fc2=nn.Linear(128,128)\n",
    "        self.measure_fc3=nn.Linear(128,128)\n",
    "\n",
    "        self.steering_branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(512 + 128, 256),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 256),\n",
    "                nn.Tanh(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, class_number)\n",
    "            ) for _ in range(3)  # 3개의 브랜치로 수정\n",
    "        ])\n",
    "\n",
    "        self.throttle_branches = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(512 + 128, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, class_number)\n",
    "\n",
    "            ) for _ in range(3)  # 3개의 브랜치로 수정\n",
    "        ])\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "    def forward(self,input,speed,command):\n",
    "        \n",
    "        x=self.conv1(input)\n",
    "        x=self.batch_norm(x)\n",
    "        x=self.relu(x)\n",
    "\n",
    "        x=self.basemodel(x)\n",
    "\n",
    "        s=self.dropout(self.relu(self.measure_fc1(speed)))\n",
    "        s=self.dropout(self.relu(self.measure_fc2(s)))\n",
    "        s=self.dropout(self.relu(self.measure_fc3(s)))\n",
    "       \n",
    "        input_cat=torch.cat((x,s),dim=-1)\n",
    "        branch_idx = torch.argmax(command, dim=1)\n",
    "        #print(branch_idx)\n",
    "\n",
    "        steering = torch.zeros((input.size(0), 1)).to(input.device)\n",
    "        throttle = torch.zeros((input.size(0), 1)).to(input.device)\n",
    "\n",
    "        for i in range(input.size(0)):  # batch 내의 각 샘플에 대해 적절한 branch 선택\n",
    "            steering[i] = self.steering_branches[branch_idx[i]](input_cat[i].unsqueeze(0))\n",
    "            steering_dist =self.steering_branches[branch_idx[i]][:5](input_cat[i].unsqueeze(0))\n",
    "            throttle[i] = self.throttle_branches[branch_idx[i]](input_cat[i].unsqueeze(0))\n",
    "            throttle_dist = self.throttle_branches[branch_idx[i]][:5](input_cat[i].unsqueeze(0))\n",
    "            dist=torch.cat((steering_dist,throttle_dist),dim=-1)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "        return throttle, steering,steering_dist,throttle_dist\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(pred,label):\n",
    "    c=nn.MSELoss().to(CFG['device'])\n",
    "    loss=torch.sqrt(c(pred,label))\n",
    "    return loss\n",
    "def I_FGSM(target_model,target,image,speed,command,target_point,epsilon,device):\n",
    "    image=image.clone().detach().to(device)\n",
    "    speed=speed.clone().detach().to(device)\n",
    "    command=command.clone().detach().to(device)\n",
    "    y_throttle,y_steering,_,_=target_model(image,speed,command)\n",
    "    \n",
    "\n",
    "\n",
    "    if target_point=='throttle':\n",
    "        y_target=y_throttle+target\n",
    "    elif target_point=='steering':\n",
    "        y_target=y_steering+target\n",
    "    else:\n",
    "        y_throttle_target=y_throttle+target\n",
    "        y_steering_target=y_steering+target\n",
    "\n",
    "    ori_image =image.clone().detach()\n",
    "    ori_speed = speed.clone().detach()\n",
    "    ori_command = command.clone().detach()\n",
    "\n",
    "    for _ in range(5):\n",
    "        image.requires_grad=True\n",
    "        y_throttle,y_steering,_,_=target_model(image,speed,command)\n",
    "        y_adv_throttle=y_throttle\n",
    "        y_adv_steering=y_steering\n",
    "        if target_point=='throttle':\n",
    "            loss_y = F.mse_loss(y_adv_throttle, y_target)\n",
    "        elif target_point=='steering':\n",
    "            loss_y = F.mse_loss(y_adv_steering, y_target)\n",
    "        else:\n",
    "            loss_y_throttle= F.mse_loss(y_adv_throttle, y_throttle_target)\n",
    "            loss_y_steering = F.mse_loss(y_adv_steering, y_steering_target)\n",
    "            loss_y=(loss_y_throttle+loss_y_steering)\n",
    "            #print(loss_y)\n",
    "        grad = torch.autograd.grad(\n",
    "                loss_y, image, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "        \n",
    "\n",
    "        adv_images = image + (2/255)* grad.sign()\n",
    "        a = torch.clamp(ori_image - epsilon, min=0)\n",
    "        b = (adv_images >= a).float() * adv_images + (\n",
    "                adv_images < a\n",
    "            ).float() * a  # nopep8\n",
    "        c = (b > ori_image + epsilon).float() * (ori_image + epsilon) + (\n",
    "                b <= ori_image + epsilon\n",
    "            ).float() * b  # nopep8\n",
    "        image = torch.clamp(c, max=1).detach()\n",
    "    return image\n",
    "\n",
    "def PGD(target_model,target,image,speed,command,target_point,epsilon,device):\n",
    "    image=image.clone().detach().to(device)\n",
    "    speed=speed.clone().detach().to(device)\n",
    "    command=command.clone().detach().to(device)\n",
    "    y_throttle,y_steering,_,_=target_model(image,speed,command)\n",
    "\n",
    "    adv_image =image.clone().detach()\n",
    "    adv_speed = speed.clone().detach()\n",
    "    adv_command = command.clone().detach()\n",
    "\n",
    "    if target_point=='throttle':\n",
    "        y_target=y_throttle+target\n",
    "    elif target_point=='steering':\n",
    "        y_target=y_steering+target\n",
    "    else:\n",
    "        y_throttle_target=y_throttle+target\n",
    "        y_steering_target=y_steering+target\n",
    "\n",
    "    for _ in range(5):\n",
    "        adv_image.requires_grad=True\n",
    "        y_adv_throttle,y_adv_steering,_,_=target_model(adv_image,adv_speed,adv_command)\n",
    "\n",
    "        if target_point=='throttle':\n",
    "            loss_y = F.mse_loss(y_adv_throttle, y_target)\n",
    "        elif target_point=='steering':\n",
    "            loss_y = F.mse_loss(y_adv_steering, y_target)\n",
    "        else:\n",
    "            loss_y_throttle= F.mse_loss(y_adv_throttle, y_throttle_target)\n",
    "            loss_y_steering = F.mse_loss(y_adv_steering, y_steering_target)\n",
    "            loss_y=(loss_y_throttle+loss_y_steering)\n",
    "\n",
    "        grad = torch.autograd.grad(\n",
    "                loss_y, adv_image, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "        adv_image = adv_image.detach() + (2/255) * grad.sign()\n",
    "        delta = torch.clamp(adv_image - image, min=-epsilon, max=epsilon)\n",
    "        adv_image = torch.clamp(image + delta, min=0, max=1).detach()\n",
    "    return adv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [07:11<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.059951 train_steering: 0.061633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [07:13<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.060038 train_steering: 0.061818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [07:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.059769 train_steering: 0.060404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [07:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.061586 train_steering: 0.090613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [06:18<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.060187 train_steering: 0.069525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [05:31<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.059729 train_steering: 0.068049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [05:29<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.059268 train_steering: 0.063714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [05:24<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.059296 train_steering: 0.060449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [05:35<00:00,  1.07it/s]\n",
      "100%|██████████| 6739/6739 [01:38<00:00, 68.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:401,Train_LOSS:0.05906 VAL_LOSS:0.00800 CURVE_LOSS:0.000050000\n",
      "label throttle: 0.31642 predict throttle: 0.43183\n",
      "label steering: 0.00000 predict steering: 0.00601\n",
      "MAE: 0.057986  RMSE: 0.057986 count: 320\n",
      "train_throttle: 0.058506 train_steering: 0.059435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [06:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.058476 train_steering: 0.061237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [05:54<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_throttle: 0.058349 train_steering: 0.064574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/358 [00:13<05:40,  1.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m total_throttle_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     36\u001b[0m total_steering_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image,speed,command,label \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m     38\u001b[0m     img\u001b[38;5;241m=\u001b[39mimage\u001b[38;5;241m.\u001b[39mto(CFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabel\u001b[38;5;241m.\u001b[39mto(CFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[12], line 109\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    107\u001b[0m image,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRandFlip(image,label)\n\u001b[0;32m    108\u001b[0m image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRandBrightness(image,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m--> 109\u001b[0m image\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandRotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m image,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRandRotateView(image,label,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_mode)\n\u001b[0;32m    111\u001b[0m image,label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRandomTranslate(image,label)\n",
      "Cell \u001b[1;32mIn[12], line 54\u001b[0m, in \u001b[0;36mRandRotation.__call__\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m     53\u001b[0m     rotate \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 54\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclip(image, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torchvision\\transforms\\functional.py:1118\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# due to current incoherence of rotation angle direction between affine and rotate implementations\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# we need to set -angle.\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m matrix \u001b[38;5;241m=\u001b[39m _get_inverse_affine_matrix(center_f, \u001b[38;5;241m-\u001b[39mangle, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m], \u001b[38;5;241m1.0\u001b[39m, [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m])\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:671\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m# grid will be generated on the same device as theta and img\u001b[39;00m\n\u001b[0;32m    669\u001b[0m grid \u001b[38;5;241m=\u001b[39m _gen_affine_grid(theta, w\u001b[38;5;241m=\u001b[39mw, h\u001b[38;5;241m=\u001b[39mh, ow\u001b[38;5;241m=\u001b[39mow, oh\u001b[38;5;241m=\u001b[39moh)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_grid_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:562\u001b[0m, in \u001b[0;36m_apply_grid_transform\u001b[1;34m(img, grid, mode, fill)\u001b[0m\n\u001b[0;32m    559\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    560\u001b[0m     img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((img, mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# Fill with required color\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\carla\\lib\\site-packages\\torch\\nn\\functional.py:4235\u001b[0m, in \u001b[0;36mgrid_sample\u001b[1;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[0;32m   4227\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   4228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault grid_sample and affine_grid behavior has changed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto align_corners=False since 1.3.0. Please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malign_corners=True if the old behavior is desired. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee the documentation of grid_sample for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4232\u001b[0m     )\n\u001b[0;32m   4233\u001b[0m     align_corners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 4235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mode_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name=['convit_base']#'mobilenetv2_100'convit_basevgg16\n",
    "\n",
    "#model_name=['mobilenetv2_100']\n",
    "\n",
    "train_mode=0 #    0:   일반 학습   1:     advtraining\n",
    "target_point='throttle&steering'\n",
    "if train_mode==0:\n",
    "\n",
    "    for model_n in model_name:\n",
    "        print(\"MODEL_NAME: \",model_n)\n",
    "        print(\"MODE: \",camera_view)\n",
    "        \n",
    "        model=BaseModel(model_name=model_n).to(CFG['device'])\n",
    "\n",
    "        flag_loss=10000\n",
    "        count=0\n",
    "        patient=500\n",
    "\n",
    "        \n",
    "        optimizer=torch.optim.Adam(model.parameters(),lr= 0.00005,betas=(0.5, 0.999), amsgrad=True)\n",
    "        #optimizer=torch.optim.SGD(model.parameters(),lr= 0.0003)\n",
    "        scedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=50)\n",
    "        #criterion=nn.L1Loss().to(CFG['device'])\n",
    "        criterion=nn.MSELoss().to(CFG['device'])\n",
    "        test_criterion=nn.MSELoss().to(CFG['device'])\n",
    "        Mae_criterion=nn.L1Loss().to(CFG['device'])\n",
    "\n",
    "        \n",
    "        for epoch in range(1,CFG['EPOCH']+1):\n",
    "            model.train()\n",
    "            train_loss=[]\n",
    "            test_loss=[]\n",
    "            test_loss_MAE=[]\n",
    "            test_loss_RMSE=[]\n",
    "            total_throttle_loss=0.0\n",
    "            total_steering_loss=0.0\n",
    "            for image,speed,command,label in tqdm(train_loader):\n",
    "                img=image.to(CFG['device'])\n",
    "                labels=label.to(CFG['device'])\n",
    "                speeds=speed.to(CFG['device'])\n",
    "                command=command.to(CFG['device'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output_throttle,output_steering,_,_=model(img,speeds,command)\n",
    "                throttle_loss=RMSE(output_throttle,labels[:,0].unsqueeze(1))\n",
    "                steering_loss=RMSE(output_steering,labels[:,1].unsqueeze(1))\n",
    "                total_steering_loss+=steering_loss.cpu().detach()\n",
    "                total_throttle_loss+=throttle_loss.cpu().detach()\n",
    "                loss=(throttle_loss*0.4+steering_loss*0.6)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "            tr_loss=np.mean(train_loss)\n",
    "\n",
    "            if epoch%10==1:\n",
    "                with torch.no_grad():\n",
    "                    throttle_output_list=[]\n",
    "                    throttle_real_list=[]\n",
    "\n",
    "                    steering_output_list=[]\n",
    "                    steering_real_list=[]\n",
    "                    model.eval()\n",
    "                    for test_image,test_speed,test_command,test_label in tqdm(test_loader):\n",
    "                        test_img=test_image.to(CFG['device'])\n",
    "                        test_speeds=test_speed.to(CFG['device'])\n",
    "                        test_labels=test_label.to(CFG['device'])\n",
    "                        test_command=test_command.to(CFG['device'])\n",
    "                        throttle_real_list.append(test_labels[0][0].item())\n",
    "                        steering_real_list.append(test_labels[0][1].item())\n",
    "\n",
    "                        test_output_throttle,test_output_steering,_,_=model(test_img,test_speeds,test_command)\n",
    "                        throttle_output_list.append(test_output_throttle[0].item())\n",
    "                        steering_output_list.append(test_output_steering[0].item())\n",
    "                        ############################################\n",
    "                        test_losses_throttle=test_criterion(test_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "                        MAE_test_throttle=Mae_criterion(test_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "                        RMSE_loss_throttle=RMSE(test_output_throttle,test_labels[:,0].unsqueeze(1).unsqueeze(1))\n",
    "\n",
    "                        test_losses_steering=test_criterion(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        MAE_test_steering=Mae_criterion(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        RMSE_loss_steering=RMSE(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        ############################################\n",
    "                        test_losses=(test_losses_throttle*0.4+test_losses_steering*0.6)\n",
    "                        MAE_test=(MAE_test_throttle*0.4+MAE_test_steering*0.6)\n",
    "                        RMSE_loss=(RMSE_loss_throttle*0.4+RMSE_loss_steering*0.6)\n",
    "\n",
    "                        test_loss_MAE.append(MAE_test.item())\n",
    "                        test_loss_RMSE.append(RMSE_loss.item())\n",
    "                        test_loss.append(test_losses.item())\n",
    "                t_loss=np.mean(test_loss)\n",
    "                MAE_loss=np.mean(test_loss_MAE)\n",
    "                RMSE_loss=np.mean(test_loss_RMSE)\n",
    "                curve_lr=optimizer.param_groups[0]['lr']\n",
    "                #plot_durations(real_list,output_list)\n",
    "\n",
    "                print(f\"EPOCH:{epoch},Train_LOSS:{tr_loss:.5f} VAL_LOSS:{t_loss:.5f} CURVE_LOSS:{curve_lr:.9f}\") \n",
    "                print(f\"label throttle: {test_labels[0][0].item():.5f} predict throttle: {test_output_throttle[0].item():.5f}\")\n",
    "                print(f\"label steering: {test_labels[0][1].item():.5f} predict steering: {test_output_steering[0].item():.5f}\")\n",
    "                print(f\"MAE: {MAE_loss:.6f}  RMSE: {RMSE_loss:.6f} count: {count}\")\n",
    "                print(f\"train_throttle: {(total_throttle_loss/len(train_loader)):.6f} train_steering: {(total_steering_loss/len(train_loader)):.6f}\")\n",
    "                plt.plot(steering_real_list)\n",
    "                plt.plot(steering_output_list)\n",
    "                plt.savefig('./'+model_n+'_steering.jpg', format='jpg')\n",
    "                plt.clf()\n",
    "                plt.plot(throttle_real_list)\n",
    "                plt.plot(throttle_output_list)\n",
    "                plt.savefig('./'+model_n+'_throttle.jpg', format='jpg')\n",
    "                plt.clf()\n",
    "                if t_loss<flag_loss:\n",
    "                    torch.save(model,'./model_list/'+str(epoch)+'_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "                    flag_loss=t_loss\n",
    "                    count=0\n",
    "                else:\n",
    "                    count+=10\n",
    "            else:\n",
    "                print(f\"train_throttle: {(total_throttle_loss/len(train_loader)):.6f} train_steering: {(total_steering_loss/len(train_loader)):.6f}\")\n",
    "            if count>patient:\n",
    "                torch.save(model,'./model_list/last_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "                break\n",
    "            scedular.step(tr_loss)\n",
    "        torch.save(model,'./model_list/last_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "\n",
    "elif train_mode==1: # 1: 적대적 학습\n",
    "    \n",
    "    for model_n in model_name:\n",
    "        print(\"MODEL_NAME: \",model_n)\n",
    "        print(\"MODE: \",camera_view)\n",
    "        \n",
    "        advtraining_net=BaseModel(model_name=model_n).to(CFG['device'])\n",
    "        #distillation_net=torch.load('F:/VSC/graduate_for_simulator/model_list/last_distillation_mobilenetv2_100_channel_9_steer_0.002392.pt').to(CFG['device'])\n",
    "        optimizer=torch.optim.Adam(advtraining_net.parameters(),lr= 0.00005,betas=(0.5, 0.999), amsgrad=True)\n",
    "        scedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=50)\n",
    "        #criterion=nn.L1Loss().to(CFG['device'])\n",
    "        criterion=nn.MSELoss().to(CFG['device'])\n",
    "        test_criterion=nn.MSELoss().to(CFG['device'])\n",
    "        Mae_criterion=nn.L1Loss().to(CFG['device'])\n",
    "\n",
    "        if model_n=='mobilenetv2_100':\n",
    "            t_model=torch.load('F:/VSC/graduate_for_simulator/model_list/best_model/901_mobilenetv2_100_channel_9_steer_0.002354.pt').to(CFG['device'])\n",
    "        elif model_n=='resnet18':\n",
    "            t_model=torch.load('F:/VSC/graduate_for_simulator/model_list/best_model/601_resnet18_channel_9_steer_0.002256.pt').to(CFG['device'])\n",
    "        elif model_n=='vgg16':\n",
    "            t_model=torch.load('F:/VSC/graduate_for_simulator/model_list/best_model/61_vgg16_channel_9_steer_0.002720.pt').to(CFG['device'])\n",
    "\n",
    "            \n",
    "        flag_loss=10000\n",
    "        count=0\n",
    "        patient=500\n",
    "\n",
    "        \n",
    "        for epoch in range(1,CFG['EPOCH']+1):\n",
    "\n",
    "            train_loss=[]\n",
    "            test_loss=[]\n",
    "            test_loss_MAE=[]\n",
    "            test_loss_RMSE=[]\n",
    "\n",
    "            \n",
    "\n",
    "            total_throttle_loss=0.0\n",
    "            total_steering_loss=0.0\n",
    "            total_dist_loss=0.0\n",
    "            for image,speed,command,label in tqdm(train_loader):\n",
    "                img=image.to(CFG['device'])\n",
    "                labels=label.to(CFG['device'])\n",
    "                speeds=speed.to(CFG['device'])\n",
    "                command=command.to(CFG['device'])\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                test_img=img[:img.shape[0]//2]\n",
    "                test_speeds=speeds[:img.shape[0]//2]\n",
    "                test_command=command[:img.shape[0]//2]\n",
    "\n",
    "                perturbed_image=PGD(target_model=advtraining_net,\n",
    "                                        target=0.3,\n",
    "                                        image=test_img,\n",
    "                                        speed=test_speeds,\n",
    "                                        command=test_command,\n",
    "                                        target_point=target_point,\n",
    "                                        epsilon=30/255,\n",
    "                                        device=CFG['device'])\n",
    "                \n",
    "                img[:img.shape[0]//2]=perturbed_image\n",
    "\n",
    "\n",
    "                output_throttle,output_steering,_,_=advtraining_net(img,speeds,command)\n",
    "    \n",
    "\n",
    "                throttle_loss=RMSE(output_throttle,labels[:,0].unsqueeze(1))\n",
    "                steering_loss=RMSE(output_steering,labels[:,1].unsqueeze(1))\n",
    "\n",
    "    \n",
    "\n",
    "                \n",
    "                total_steering_loss+=steering_loss.cpu().detach()\n",
    "                total_throttle_loss+=throttle_loss.cpu().detach()\n",
    "                loss=(throttle_loss*0.4+steering_loss*0.6)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "            tr_loss=np.mean(train_loss)\n",
    "\n",
    "\n",
    "            if epoch%10==1:\n",
    "                with torch.no_grad():\n",
    "                    throttle_output_list=[]\n",
    "                    throttle_real_list=[]\n",
    "\n",
    "                    steering_output_list=[]\n",
    "                    steering_real_list=[]\n",
    "                    advtraining_net.eval()\n",
    "                    for test_image,test_speed,test_command,test_label in tqdm(test_loader):\n",
    "                        test_img=test_image.to(CFG['device'])\n",
    "                        test_speeds=test_speed.to(CFG['device'])\n",
    "                        test_labels=test_label.to(CFG['device'])\n",
    "                        test_command=test_command.to(CFG['device'])\n",
    "                        throttle_real_list.append(test_labels[0][0].item())\n",
    "                        steering_real_list.append(test_labels[0][1].item())\n",
    "\n",
    "                        test_output_throttle,test_output_steering,_,_=advtraining_net(test_img,test_speeds,test_command)\n",
    "                        throttle_output_list.append(test_output_throttle[0].item())\n",
    "                        steering_output_list.append(test_output_steering[0].item())\n",
    "                        ############################################\n",
    "                        test_losses_throttle=test_criterion(test_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "                        MAE_test_throttle=Mae_criterion(test_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "                        RMSE_loss_throttle=RMSE(test_output_throttle,test_labels[:,0].unsqueeze(1).unsqueeze(1))\n",
    "\n",
    "                        test_losses_steering=test_criterion(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        MAE_test_steering=Mae_criterion(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        RMSE_loss_steering=RMSE(test_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "                        ############################################\n",
    "                        test_losses=(test_losses_throttle*0.4+test_losses_steering*0.6)\n",
    "                        MAE_test=(MAE_test_throttle*0.4+MAE_test_steering*0.6)\n",
    "                        RMSE_loss=(RMSE_loss_throttle*0.4+RMSE_loss_steering*0.6)\n",
    "\n",
    "                        test_loss_MAE.append(MAE_test.item())\n",
    "                        test_loss_RMSE.append(RMSE_loss.item())\n",
    "                        test_loss.append(test_losses.item())\n",
    "                t_loss=np.mean(test_loss)\n",
    "                MAE_loss=np.mean(test_loss_MAE)\n",
    "                RMSE_loss=np.mean(test_loss_RMSE)\n",
    "                curve_lr=optimizer.param_groups[0]['lr']\n",
    "                #plot_durations(real_list,output_list)\n",
    "\n",
    "                print(f\"EPOCH:{epoch},Train_LOSS:{tr_loss:.5f} VAL_LOSS:{t_loss:.5f} CURVE_LOSS:{curve_lr:.9f}\") \n",
    "                print(f\"label throttle: {test_labels[0][0].item():.5f} predict throttle: {test_output_throttle[0].item():.5f}\")\n",
    "                print(f\"label steering: {test_labels[0][1].item():.5f} predict steering: {test_output_steering[0].item():.5f}\")\n",
    "                print(f\"MAE: {MAE_loss:.6f}  RMSE: {RMSE_loss:.6f} count: {count}\")\n",
    "                print(f\"train_throttle: {(total_throttle_loss/len(train_loader)):.6f} train_steering: {(total_steering_loss/len(train_loader)):.6f}\")\n",
    "                plt.plot(steering_real_list)\n",
    "                plt.plot(steering_output_list)\n",
    "                plt.savefig('./'+model_n+'_advtraining_steering.jpg', format='jpg')\n",
    "                plt.clf()\n",
    "                plt.plot(throttle_real_list)\n",
    "                plt.plot(throttle_output_list)\n",
    "                plt.savefig('./'+model_n+'_advtraining_throttle.jpg', format='jpg')\n",
    "                plt.clf()\n",
    "                if t_loss<flag_loss:\n",
    "                    torch.save(advtraining_net,'./model_list/advtraining_'+str(epoch)+'_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "                    flag_loss=t_loss\n",
    "                    count=0\n",
    "                else:\n",
    "                    count+=10\n",
    "            else:\n",
    "                print(f\"train_throttle: {(total_throttle_loss/len(train_loader)):.6f} train_steering: {(total_steering_loss/len(train_loader)):.6f} train_dist: {(total_dist_loss/len(train_loader)):.6f}\")\n",
    "            \n",
    "            # if epoch%10==1:\n",
    "            #     test_loss_MAE=[]\n",
    "            #     test_loss_MSE=[]\n",
    "            #     test_loss_RMSE=[]\n",
    "\n",
    "            #     mse_criterion=nn.MSELoss().to(CFG['device'])\n",
    "            #     mae_criterion=nn.L1Loss().to(CFG['device'])\n",
    "            #     real_label=[]\n",
    "            #     predict_adv_label=[]\n",
    "            #     predict_label=[]\n",
    "            #     total_diff = np.array([])\n",
    "            #     attack_method='PGD'#opt,MI-FGSM, I-FGSM,PGD,CW,None\n",
    "            #     attack_point=2 #0: throttle 1: steering 2: throttle&steering\n",
    "\n",
    "\n",
    "            #     Transfer_attack=False\n",
    "\n",
    "            #     feature_squeezing_flag=False\n",
    "            #     gradient_mode=False\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "            #     main_model=advtraining_net.eval()\n",
    "            #     t_model=t_model.eval()\n",
    "            #     for i,(test_image,test_speed,test_command,test_label) in enumerate(tqdm(test_loader)):\n",
    "                    \n",
    "            #         test_img=test_image.to(CFG['device'])\n",
    "            #         test_speeds=test_speed.to(CFG['device'])\n",
    "            #         test_labels=test_label.to(CFG['device'])\n",
    "            #         test_command=test_command.to(CFG['device'])\n",
    "            #         #print(test_labels[0][1])\n",
    "\n",
    "            #         if attack_method=='PGD':\n",
    "            #             perturbed_image=PGD(target_model=main_model,\n",
    "            #                                     target=0.3,\n",
    "            #                                     image=test_img,\n",
    "            #                                     speed=test_speeds,\n",
    "            #                                     command=test_command,\n",
    "            #                                     target_point=target_point,\n",
    "            #                                     epsilon=8/255,\n",
    "            #                                     device=CFG['device'])\n",
    "                    \n",
    "\n",
    "            #         test_adv_output_throttle,test_adv_output_steering,_,_=main_model(perturbed_image,test_speeds,test_command) #어택\n",
    "\n",
    "            #         test_output_throttle,test_output_steering,_,_=t_model(test_img,test_speeds,test_command) #노말\n",
    "                    \n",
    "            #         if attack_point==0:#0: throttle\n",
    "            #             throttle_diff = (test_adv_output_throttle - test_output_throttle).detach().cpu().numpy()\n",
    "            #             diff = np.squeeze((throttle_diff))\n",
    "            #         elif attack_point==1:#1: steering\n",
    "            #             steering_diff = (test_adv_output_steering - test_output_steering).detach().cpu().numpy() \t\n",
    "            #             diff = np.squeeze((steering_diff))\n",
    "            #         else:#2:throttle&steering\n",
    "            #             throttle_diff = (test_adv_output_throttle - test_output_throttle).detach().cpu().numpy()\n",
    "            #             steering_diff = (test_adv_output_steering - test_output_steering).detach().cpu().numpy() \n",
    "            #             diff = np.squeeze((steering_diff+throttle_diff))\n",
    "\n",
    "\n",
    "\n",
    "            #         RMSE_throttle_loss=RMSE(test_adv_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "            #         RMSE_steering_loss=RMSE(test_adv_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "            #         RMSE_loss=(RMSE_throttle_loss*0.4+RMSE_steering_loss*0.6)\n",
    "            #         test_loss_RMSE.append(RMSE_loss.item())\n",
    "\n",
    "            #         MSE_throttle_loss=mse_criterion(test_adv_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "            #         MSE_steering_loss=mse_criterion(test_adv_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "            #         MSE_loss=(MSE_throttle_loss*0.4+MSE_steering_loss*0.6)\n",
    "            #         test_loss_MSE.append(MSE_loss.item())\n",
    "\n",
    "            #         MAE_throttle_loss=mae_criterion(test_adv_output_throttle,test_labels[:,0].unsqueeze(1))\n",
    "            #         MAE_steering_loss=mae_criterion(test_adv_output_steering,test_labels[:,1].unsqueeze(1))\n",
    "            #         MAE_loss=(MAE_throttle_loss*0.4+MAE_steering_loss*0.6)\n",
    "            #         test_loss_MAE.append(MAE_loss.item())\n",
    "\n",
    "            #         total_diff = np.concatenate((total_diff, [diff]))\t\n",
    "\n",
    "\n",
    "            #         predict_adv_label.append(test_adv_output_steering[0][0].cpu().detach())\n",
    "            #         predict_label.append(test_output_steering[0][0].cpu().detach())\n",
    "            #         if i%100==0:\n",
    "            #             MSE_loss=np.mean(test_loss_MSE)\n",
    "            #             MAE_loss=np.mean(test_loss_MAE)\n",
    "            #             RMSE_loss=np.mean(test_loss_RMSE)\n",
    "            #             success_ = len(total_diff[abs(total_diff) >= 0.3]) \n",
    "            #             print(\"진짜예측과 가짜 예측의 차이 평균: \", np.mean(total_diff))\n",
    "            #             print(\"공격 성공: \", success_/(i+1)*100)\n",
    "            #             print(\"RMSE: \",RMSE_loss)\n",
    "            #             print(\"MSE: \",MSE_loss)\n",
    "            #             print(\"MAE: \",MAE_loss)\n",
    "            #             print(\"=====================================================\")\n",
    "            #             break\n",
    "                    \n",
    "            \n",
    "            if count>patient:\n",
    "                torch.save(advtraining_net,'./model_list/last_advtraining_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "                break\n",
    "            scedular.step(tr_loss)\n",
    "        torch.save(advtraining_net,'./model_list/last_advtraining_'+model_n+'_'+camera_view+'_'+target_label_mode+'_'+str(t_loss)[:8]+'.pt')\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advtraining_net=BaseModel(model_name=model_n).to(CFG['device'])\n",
    "for image,speed,command,label in tqdm(train_loader):\n",
    "        img=image.to(CFG['device'])\n",
    "        labels=label.to(CFG['device'])\n",
    "        speeds=speed.to(CFG['device'])\n",
    "        command=command.to(CFG['device'])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        test_img=img[:img.shape[0]//2]\n",
    "        test_speeds=speeds[:img.shape[0]//2]\n",
    "        test_command=command[:img.shape[0]//2]\n",
    "\n",
    "        perturbed_image=PGD(target_model=advtraining_net,\n",
    "                                target=0.3,\n",
    "                                image=test_img,\n",
    "                                speed=test_speeds,\n",
    "                                command=test_command,\n",
    "                                target_point=target_point,\n",
    "                                epsilon=30/255,\n",
    "                                device=CFG['device'])\n",
    "        \n",
    "        img[:img.shape[0]//2]\n",
    "\n",
    "\n",
    "\n",
    "        output_throttle,output_steering,_,_=advtraining_net(img,speeds,command)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('F:/VSC/graduate_for_simulator/model_list/best_model/61_vgg16_channel_9_steer_0.002720.pt').to(CFG['device'])\n",
    "test_loader=DataLoader(val_transform_dataset,batch_size=1,shuffle=False)\n",
    "real_label=[]\n",
    "predict_label=[]\n",
    "t=[]\n",
    "test_criterion=nn.MSELoss().to(CFG['device'])\n",
    "# model=BaseModel(model_name='resnet18').to(CFG['device'])\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for test_image,test_speed,test_command,test_label in tqdm(test_loader):\n",
    "        \n",
    "        test_img=test_image.to(CFG['device'])\n",
    "        test_speeds=test_speed.to(CFG['device'])\n",
    "        test_labels=test_label.to(CFG['device'])\n",
    "        test_command=test_command.to(CFG['device'])\n",
    "\n",
    "        \n",
    "        test_output_throttle,test_output_steering=model(test_img,test_speeds,test_command)\n",
    "        #loss=test_criterion(output,test_label)\n",
    "        #t.append(loss.cpu().detach())\n",
    "        predict_label.append(test_output_steering[0][0].cpu().detach())\n",
    "        real_label.append(test_labels[0][1].cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(predict_label)\n",
    "plt.plot(real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image=test_image.to(CFG['device'])\n",
    "# label=test_label.to(CFG['device'])\n",
    "# output=model(image)\n",
    "# print('out_put: ',output)\n",
    "# print('label: ',label)\n",
    "# print('loss: ',loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
